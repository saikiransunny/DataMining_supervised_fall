geom_line(aes(y = boot_error, colour = "boot_error"))
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv"), linetype = "dashed") +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv"), linetype = "dashed") +
geom_line(aes(y = boot_error, colour = "boot_error")) +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE")
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv"), linetype = "dashed") +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv"), linetype = "dashed") +
geom_line(aes(y = boot_error, colour = "boot_error")) +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE") +
theme(plot.title = element_text(hjust = 0.5))
AIC = c()
BIC = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
train = train[, c(1,temp)]
glm_model = glm(lcavol~., data = train, family = "gaussian")
AIC = append(AIC, AIC(glm_model))
BIC = append(BIC, BIC(glm_model))
}
AIC_val = c()
BIC_val = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
train_subset = train[, c(1,temp)]
glm_model = glm(lcavol~., data = train_subset, family = "gaussian")
AIC_val = append(AIC_val, AIC(glm_model))
BIC_val = append(BIC_val, BIC(glm_model))
}
i =3
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
temp
i = 8
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
temp
rm(list = ls(all = T))
setwd("/home/saikiran/Fall 2017/applied_stats_rachael/Homeworks/HW4/codes")
library(lasso2)
prostate = data(Prostate)
#check the sanity of the data.
sum(is.na(Prostate))
#divide train and test.
set.seed(1234)
train_index = sample(1:nrow(Prostate), 0.8*nrow(Prostate))
train = Prostate[train_index,]
test = Prostate[-train_index,]
library(leaps)
regfit.full <- regsubsets(lcavol~., data = train, nbest = 1, nvmax = 8, method = "exhaustive")
my_sum <- summary(regfit.full)
my_sum
#2 feature regression is best.
which(my_sum$cp == min(my_sum$cp))
#lcp and lpsa are the best 2 feature subset.
which(my_sum$outmat[2,] == "*")
library(stats)
AIC_val = c()
BIC_val = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
train_subset = train[, c(1,temp)]
glm_model = glm(lcavol~., data = train_subset, family = "gaussian")
AIC_val = append(AIC_val, AIC(glm_model))
BIC_val = append(BIC_val, BIC(glm_model))
}
AIC_val
BIC_val
features = seq(1,8)
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = AIC_val, colour = "AIC_val")) +
geom_line(aes(y = BIC_val, colour = "BIC_val")) +
ggtitle("AIC vs BIC") + xlab("No of features") + ylab("values") +
theme(plot.title = element_text(hjust = 0.5))
plot_dataframe = data.frame(features, AIC_val, BIC_val)
library(ggplot2)
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = AIC_val, colour = "AIC_val")) +
geom_line(aes(y = BIC_val, colour = "BIC_val")) +
ggtitle("AIC vs BIC") + xlab("No of features") + ylab("values") +
theme(plot.title = element_text(hjust = 0.5))
rm(list = ls(all = T))
setwd("/home/saikiran/Fall 2017/applied_stats_rachael/Homeworks/HW4/codes")
library(lasso2)
prostate = data(Prostate)
#check the sanity of the data.
sum(is.na(Prostate))
#divide train and test.
set.seed(1234)
train_index = sample(1:nrow(Prostate), 0.8*nrow(Prostate))
train = Prostate[train_index,]
test = Prostate[-train_index,]
library(leaps)
regfit.full <- regsubsets(lcavol~., data = train, nbest = 1, nvmax = 8, method = "exhaustive")
my_sum <- summary(regfit.full)
my_sum
#2 feature regression is best.
which(my_sum$cp == min(my_sum$cp))
#lcp and lpsa are the best 2 feature subset.
which(my_sum$outmat[2,] == "*")
library(stats)
AIC_val = c()
BIC_val = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
train_subset = train[, c(1,temp)]
glm_model = glm(lcavol~., data = train_subset, family = "gaussian")
AIC_val = append(AIC_val, AIC(glm_model))
BIC_val = append(BIC_val, BIC(glm_model))
}
features = seq(1,8)
plot_dataframe = data.frame(features, AIC_val, BIC_val)
library(ggplot2)
#plotting
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = AIC_val, colour = "AIC_val")) +
geom_line(aes(y = BIC_val, colour = "BIC_val")) +
ggtitle("AIC vs BIC") + xlab("No of features") + ylab("values") +
theme(plot.title = element_text(hjust = 0.5))
CV = function(dataframe, fold = 5){
dataframe<-dataframe[sample(nrow(dataframe)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(dataframe)),breaks=fold,labels=FALSE)
#Perform 10 fold cross validation
results = c()
for(i in 2:fold){
#Segement your data by fold using the which() function
testIndexes = which(folds==i,arr.ind=TRUE)
testData = dataframe[testIndexes, ]
trainData = dataframe[-testIndexes, ]
#train and test with glm.
glm_model = glm(lcavol~., trainData, family = "gaussian")
predictions = predict(glm_model, testData)
results = append(results, (1/length(predictions))*sum((predictions - testData$lcavol)^2))
}
return(mean(results))
}
#5CV
#####
train_error_5cv = c()
test_error_5cv = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
red.training = train[, c(1,temp)]
red.testing = test[,c(1,temp)]
red.fit = glm(lcavol~., data = red.training, family = "gaussian")
pred.test = predict(red.fit, red.testing)
test.error = (1/length(red.testing$lcavol))*sum((pred.test - red.testing$lcavol)^2)
train.error = CV(red.training, 5)
train_error_5cv = append(train_error_5cv, train.error)
test_error_5cv = append(test_error_5cv, test.error)
}
#####
#10CV
#####
train_error_10cv = c()
test_error_10cv = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
red.training = train[, c(1,temp)]
red.testing = test[,c(1,temp)]
red.fit = glm(lcavol~., data = red.training, family = "gaussian")
pred.test = predict(red.fit, red.testing)
test.error = (1/length(red.testing$lcavol))*sum((pred.test - red.testing$lcavol)^2)
train.error = CV(red.training, 10)
train_error_10cv = append(train_error_10cv, train.error)
test_error_10cv = append(test_error_10cv, test.error)
}
#####
# create functions that feed into "bootpred"
beta.fit <- function(X,Y){
lsfit(X,Y)
}
beta.predict <- function(fit, X){
cbind(1,X)%*%fit$coef
}
sq.error <- function(Y,Yhat){
(Y-Yhat)^2
}
# Create X and Y
X = train[,2:9]
Y = train[,1]
# Generalize it, and search over the best possible subsets of size "k"
boot_error = c()
for (i in 1:8){
# Pull out the model
temp = which(my_sum$outmat[i,] == "*")
res = bootpred(X[,temp], Y, nboot = 50, theta.fit = beta.fit, theta.predict = beta.predict, err.meas = sq.error)
boot_error = c(boot_error, res[[3]])
}
library(ggplot2)
features = seq(1,8)
plot_dataframe = data.frame(features, train_error_5cv, test_error_5cv, train_error_10cv, test_error_10cv,
boot_error)
#plotting
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv"), linetype = "dashed") +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv"), linetype = "dashed") +
geom_line(aes(y = boot_error, colour = "boot_error")) +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) + geom_point(size = 2) +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv"), linetype = "dashed") +geom_point(size = 2) +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) + geom_point(size = 2) +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv"), linetype = "dashed") + geom_point(size = 2) +
geom_line(aes(y = boot_error, colour = "boot_error")) + geom_point(size = 2) +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) + geom_point(aes(y = train_error_5cv),size = 2) +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv"), linetype = "dashed") + geom_point(aes(y = train_error_5cv),size = 2) +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) + geom_point(aes(y = train_error_5cv),size = 2) +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv"), linetype = "dashed") + geom_point(aes(y = train_error_5cv),size = 2) +
geom_line(aes(y = boot_error, colour = "boot_error")) + geom_point(aes(y = train_error_5cv),size = 2) +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) + geom_point(aes(y = train_error_5cv),size = 1.5) +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv"), linetype = "dashed") + geom_point(aes(y = test_error_5cv),size = 1.5) +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) + geom_point(aes(y = train_error_10cv),size = 1.5) +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv"), linetype = "dashed") + geom_point(aes(y = test_error_10cv),size = 1.5) +
geom_line(aes(y = boot_error, colour = "boot_error")) + geom_point(aes(y = boot_error),size = 1.5) +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) + geom_point(aes(y = train_error_5cv),
size = 1.5, colour = "train_error_5cv") +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv")) + geom_point(aes(y = test_error_5cv),
size = 1.5, colour = "test_error_5cv") +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) + geom_point(aes(y = train_error_10cv),
size = 1.5, colour = "train_error_10cv") +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv")) + geom_point(aes(y = test_error_10cv),
size = 1.5, colour = "test_error_10cv") +
geom_line(aes(y = boot_error, colour = "boot_error")) + geom_point(aes(y = boot_error),size = 1.5,
colour = "boot_error") +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) + geom_point(aes(y = train_error_5cv),
size = 1.5) +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv")) + geom_point(aes(y = test_error_5cv),
size = 1.5) +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) + geom_point(aes(y = train_error_10cv),
size = 1.5) +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv")) + geom_point(aes(y = test_error_10cv),
size = 1.5) +
geom_line(aes(y = boot_error, colour = "boot_error")) + geom_point(aes(y = boot_error),size = 1.5) +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE") +
theme(plot.title = element_text(hjust = 0.5))
rm(list = ls(all = T))
setwd("/home/saikiran/Fall 2017/applied_stats_rachael/Homeworks/HW4/codes")
library(lasso2)
prostate = data(Prostate)
#check the sanity of the data.
sum(is.na(Prostate))
#divide train and test.
set.seed(1234)
train_index = sample(1:nrow(Prostate), 0.8*nrow(Prostate))
train = Prostate[train_index,]
test = Prostate[-train_index,]
library(leaps)
regfit.full <- regsubsets(lcavol~., data = train, nbest = 1, nvmax = 8, method = "exhaustive")
my_sum <- summary(regfit.full)
my_sum
#2 feature regression is best.
which(my_sum$cp == min(my_sum$cp))
#lcp and lpsa are the best 2 feature subset.
which(my_sum$outmat[2,] == "*")
library(stats)
AIC_val = c()
BIC_val = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
train_subset = train[, c(1,temp)]
glm_model = glm(lcavol~., data = train_subset, family = "gaussian")
AIC_val = append(AIC_val, AIC(glm_model))
BIC_val = append(BIC_val, BIC(glm_model))
}
features = seq(1,8)
plot_dataframe = data.frame(features, AIC_val, BIC_val)
library(ggplot2)
#plotting
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = AIC_val, colour = "AIC_val")) +
geom_line(aes(y = BIC_val, colour = "BIC_val")) +
ggtitle("AIC vs BIC") + xlab("No of features") + ylab("values") +
theme(plot.title = element_text(hjust = 0.5))
CV = function(dataframe, fold = 5){
dataframe<-dataframe[sample(nrow(dataframe)),]
#Create 10 equally size folds
folds <- cut(seq(1,nrow(dataframe)),breaks=fold,labels=FALSE)
#Perform 10 fold cross validation
results = c()
for(i in 2:fold){
#Segement your data by fold using the which() function
testIndexes = which(folds==i,arr.ind=TRUE)
testData = dataframe[testIndexes, ]
trainData = dataframe[-testIndexes, ]
#train and test with glm.
glm_model = glm(lcavol~., trainData, family = "gaussian")
predictions = predict(glm_model, testData)
results = append(results, (1/length(predictions))*sum((predictions - testData$lcavol)^2))
}
return(mean(results))
}
#5CV
#####
train_error_5cv = c()
test_error_5cv = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
red.training = train[, c(1,temp)]
red.testing = test[,c(1,temp)]
red.fit = glm(lcavol~., data = red.training, family = "gaussian")
pred.test = predict(red.fit, red.testing)
test.error = (1/length(red.testing$lcavol))*sum((pred.test - red.testing$lcavol)^2)
train.error = CV(red.training, 5)
train_error_5cv = append(train_error_5cv, train.error)
test_error_5cv = append(test_error_5cv, test.error)
}
#####
#10CV
#####
train_error_10cv = c()
test_error_10cv = c()
for (i in 1:8){
temp = which(my_sum$outmat[i,] == "*")
temp = temp + 1
red.training = train[, c(1,temp)]
red.testing = test[,c(1,temp)]
red.fit = glm(lcavol~., data = red.training, family = "gaussian")
pred.test = predict(red.fit, red.testing)
test.error = (1/length(red.testing$lcavol))*sum((pred.test - red.testing$lcavol)^2)
train.error = CV(red.training, 10)
train_error_10cv = append(train_error_10cv, train.error)
test_error_10cv = append(test_error_10cv, test.error)
}
#####
# create functions that feed into "bootpred"
beta.fit <- function(X,Y){
lsfit(X,Y)
}
beta.predict <- function(fit, X){
cbind(1,X)%*%fit$coef
}
sq.error <- function(Y,Yhat){
(Y-Yhat)^2
}
# Create X and Y
X = train[,2:9]
Y = train[,1]
# Generalize it, and search over the best possible subsets of size "k"
boot_error = c()
for (i in 1:8){
# Pull out the model
temp = which(my_sum$outmat[i,] == "*")
res = bootpred(X[,temp], Y, nboot = 50, theta.fit = beta.fit, theta.predict = beta.predict, err.meas = sq.error)
boot_error = c(boot_error, res[[3]])
}
library(ggplot2)
features = seq(1,8)
plot_dataframe = data.frame(features, train_error_5cv, test_error_5cv, train_error_10cv, test_error_10cv,
boot_error)
#plotting
ggplot(plot_dataframe, aes(features)) +
geom_line(aes(y = train_error_5cv, colour = "train_error_5cv")) + geom_point(aes(y = train_error_5cv),
size = 1.5) +
geom_line(aes(y = test_error_5cv, colour = "test_error_5cv")) + geom_point(aes(y = test_error_5cv),
size = 1.5) +
geom_line(aes(y = train_error_10cv, colour = "train_error_10cv")) + geom_point(aes(y = train_error_10cv),
size = 1.5) +
geom_line(aes(y = test_error_10cv, colour = "test_error_10cv")) + geom_point(aes(y = test_error_10cv),
size = 1.5) +
geom_line(aes(y = boot_error, colour = "boot_error")) + geom_point(aes(y = boot_error),size = 1.5) +
ggtitle("Different errors.") + xlab("No of features") + ylab("MSE") +
theme(plot.title = element_text(hjust = 0.5))
install.packages("kernlab")
library(kernlab)
data("spam")
sum(is.na(spam))
names(spam)
library(randomForest)
?randomforest
?randomForest
rf.model = randomForest(type~., spam, ntree = 100)
rf.model[[10]]
rf.model[[11]]
rf.model[[1]]
rf.model[[3]]
rf.model[[4]]
rf.model[[]]
rf.model[[5]]
rf.model[[6]]
rf.model[[7]]
rf.model[[8]]
rf.model[[9]]
rf.model$err.rate
plot(rf.model$err.rate)
plot(rf.model$err.rate[,1])
#split train and test.
set.seed(1234)
train_index = sample(1:nrow(spam), 0.8*nrow(spam))
train = spam[train_index,]
test = spam[-train_index,]
table(train$type)
plot(rf.model)
?randomForest
library(MLmetrics)
library(randomForest)
library(MLmetrics)
mtrylist = c()
accuracylist = c()
#select the best m.
for(i in seq(5,55,5)){
rf.model = randomForest(type~., spam, ntree = 100, mtry = i)
model_predictions = predict(rf.model, test)
mtrylist = append(mtrylist, i)
accuracylist = append(accuracylist, MLmetrics::Accuracy(model_predictions, test$type))
print(i)
}
accuracylist
mtrylist = c()
accuracylist = c()
#select the best m.
for(i in seq(2,15,2)){
rf.model = randomForest(type~., spam, ntree = 100, mtry = i)
model_predictions = predict(rf.model, test)
mtrylist = append(mtrylist, i)
accuracylist = append(accuracylist, MLmetrics::Accuracy(model_predictions, test$type))
print(i)
}
accuracylist
rep(0,5)
#choosing mtry = [2,4,6,8,10] for plotting.
######
mtrylist = c()
OOBlist = rep(0,100)
test_error = c()
#select the best m.
for(i in c(2,4,6,8,10)){
rf.model = randomForest(type~., spam, ntree = 100, mtry = i)
model_predictions = predict(rf.model, test)
OOBlist = cbind(OOBlist, rf.model$err.rate[,c(1)])
mtrylist = append(mtrylist, i)
test_error = append(test_error, MLmetrics::Accuracy(model_predictions, test$type))
print(i)
}
plot_dataframe = data.frame(mtrylist, test_error)
names(plot_dataframe) = c("mtry", "accuracy")
library(ggplot2)
ggplot(plot_dataframe, aes(x = mtry, y = accuracy)) + geom_line() + geom_point()
ggplot(plot_dataframe, aes(x = mtry, y = accuracy)) + geom_line() + geom_point() +
ggtitle("Mtry vs Accuracy") + theme(plot.title = element_text(hjust = 0.5))
OOBlist_plot = data.frame(OOBlist)
View(OOBlist_plot)
OOBlist_plot = data.frame(OOBlist)[,-c(1)]
View(OOBlist_plot)
View(plot_dataframe)
names(OOBlist_plot) = c("mtry_2", "mtry_4","mtry_6","mtry_8","mtry_10",)
names(OOBlist_plot) = c("mtry_2", "mtry_4","mtry_6","mtry_8","mtry_10")
OOBlist_plot$NTrees = seq(1, 100)
View(OOBlist_plot)
ggplot(OOBlist_plot, aes(NTrees)) +
geom_line(aes(y = mtry_2, colour = "mtry_2")) + geom_point(aes(y = mtry_2), size = 1.5) +
geom_line(aes(y = mtry_4, colour = "mtry_2")) + geom_point(aes(y = mtry_4), size = 1.5) +
geom_line(aes(y = mtry_6, colour = "mtry_2")) + geom_point(aes(y = mtry_6), size = 1.5) +
geom_line(aes(y = mtry_8, colour = "mtry_2")) + geom_point(aes(y = mtry_8), size = 1.5) +
geom_line(aes(y = mtry_10, colour = "mtry_2")) + geom_point(aes(y = mtry_10), size = 1.5) +
ggtitle("Out of Bag Errors.") + xlab("No of features") + ylab("OOB Error") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(OOBlist_plot, aes(NTrees)) +
geom_line(aes(y = mtry_2, colour = "mtry_2")) + geom_point(aes(y = mtry_2), size = 0.5) +
geom_line(aes(y = mtry_4, colour = "mtry_2")) + geom_point(aes(y = mtry_4), size = 0.5) +
geom_line(aes(y = mtry_6, colour = "mtry_2")) + geom_point(aes(y = mtry_6), size = 0.5) +
geom_line(aes(y = mtry_8, colour = "mtry_2")) + geom_point(aes(y = mtry_8), size = 0.5) +
geom_line(aes(y = mtry_10, colour = "mtry_2")) + geom_point(aes(y = mtry_10), size = 0.5) +
ggtitle("Out of Bag Errors.") + xlab("No of features") + ylab("OOB Error") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(OOBlist_plot, aes(NTrees)) +
geom_line(aes(y = mtry_2, colour = "mtry_2")) + geom_point(aes(y = mtry_2), size = 0.5) +
geom_line(aes(y = mtry_4, colour = "mtry_4")) + geom_point(aes(y = mtry_4), size = 0.5) +
geom_line(aes(y = mtry_6, colour = "mtry_6")) + geom_point(aes(y = mtry_6), size = 0.5) +
geom_line(aes(y = mtry_8, colour = "mtry_8")) + geom_point(aes(y = mtry_8), size = 0.5) +
geom_line(aes(y = mtry_10, colour = "mtry_10")) + geom_point(aes(y = mtry_10), size = 0.5) +
ggtitle("Out of Bag Errors.") + xlab("No of features") + ylab("OOB Error") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(OOBlist_plot, aes(NTrees)) +
geom_line(aes(y = mtry_2, colour = "mtry_2")) + geom_point(aes(y = mtry_2), size = 0.3) +
geom_line(aes(y = mtry_4, colour = "mtry_4")) + geom_point(aes(y = mtry_4), size = 0.3) +
geom_line(aes(y = mtry_6, colour = "mtry_6")) + geom_point(aes(y = mtry_6), size = 0.3) +
geom_line(aes(y = mtry_8, colour = "mtry_8")) + geom_point(aes(y = mtry_8), size = 0.3) +
geom_line(aes(y = mtry_10, colour = "mtry_10")) + geom_point(aes(y = mtry_10), size = 0.3) +
ggtitle("Out of Bag Errors.") + xlab("No of features") + ylab("OOB Error") +
theme(plot.title = element_text(hjust = 0.5))
ggplot(plot_dataframe, aes(x = mtry, y = accuracy)) + geom_line() + geom_point() +
ggtitle("Mtry vs Accuracy") + theme(plot.title = element_text(hjust = 0.5))
